{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665c0490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gmaps \n",
    "import gmaps.datasets\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error\n",
    "from scipy.stats import boxcox\n",
    "from scipy.spatial import KDTree\n",
    "pd.options.display.max_rows = 50\n",
    "pd.options.display.max_columns = 999\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d89785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the custom functions that we will be using: import_dataset, rf_model, rf_clustering, evaluate\n",
    "from helper_functions import import_dataset, rf_model, rf_clustering, evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1696d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(r\"..\\Data_Midterm.xls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b277f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = df.drop(columns=['id', \"date\", 'sqft_above'])\n",
    "    df = df[df[\"bedrooms\"] <= 6]\n",
    "    df = df[(df[\"bathrooms\"] < 6) & (df[\"bathrooms\"] >= 1)]\n",
    "    df = df[df[\"sqft_living\"] <= 5000]\n",
    "    df = df[df[\"sqft_living15\"] <= 5000]\n",
    "    df = df[df[\"sqft_lot\"] <= 15000]\n",
    "    df = df[df[\"sqft_lot15\"] <= 15000]\n",
    "    df.loc[df[\"view\"] != 0, \"view\"] = 1\n",
    "    df = df[df[\"condition\"] > 2]\n",
    "    df.loc[df[\"sqft_basement\"] != 0, \"sqft_basement\"] = 1\n",
    "    df.loc[(df[\"yr_renovated\"]!=0)&(df[\"yr_renovated\"]<1990), \"yr_renovated\"] = 1\n",
    "    df.loc[df[\"yr_renovated\"]>=1990, \"yr_renovated\"] = 2\n",
    "    \n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d5d04a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17821 entries, 0 to 21595\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   bedrooms       17821 non-null  int64  \n",
      " 1   bathrooms      17821 non-null  float64\n",
      " 2   sqft_living    17821 non-null  int64  \n",
      " 3   sqft_lot       17821 non-null  int64  \n",
      " 4   floors         17821 non-null  float64\n",
      " 5   waterfront     17821 non-null  int64  \n",
      " 6   view           17821 non-null  int64  \n",
      " 7   condition      17821 non-null  int64  \n",
      " 8   grade          17821 non-null  int64  \n",
      " 9   sqft_basement  17821 non-null  int64  \n",
      " 10  yr_built       17821 non-null  int64  \n",
      " 11  yr_renovated   17821 non-null  int64  \n",
      " 12  zipcode        17821 non-null  int64  \n",
      " 13  lat            17821 non-null  float64\n",
      " 14  long           17821 non-null  float64\n",
      " 15  sqft_living15  17821 non-null  int64  \n",
      " 16  sqft_lot15     17821 non-null  int64  \n",
      " 17  price          17821 non-null  int64  \n",
      "dtypes: float64(4), int64(14)\n",
      "memory usage: 2.6 MB\n"
     ]
    }
   ],
   "source": [
    "clean_dataset = clean_data(dataset)\n",
    "clean_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2076c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Model Performance---\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "\n",
      "Average Absolute Error: 109609.6 dollars.\n",
      "Mean squared error: 162025.97\n",
      "Accuracy = 76.48%.\n",
      "Coefficient of determination: 0.67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(clean_dataset.drop([\"price\", \"yr_built\"],axis=1), clean_dataset[\"price\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "reg = LinearRegression()\n",
    "pipe = make_pipeline(scaler, reg)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_predict = pipe.predict(X_test)\n",
    "\n",
    "results = evaluate(pipe, X_test, y_test, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609e6635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9209944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\carlo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Model Performance---\n",
      "RandomForestRegressor(bootstrap=False, max_depth=100, max_features='sqrt',\n",
      "                      n_estimators=300)\n",
      "\n",
      "Average Absolute Error: 56661.0 dollars.\n",
      "Mean squared error: 97008.04\n",
      "Accuracy = 88.01%.\n",
      "Coefficient of determination: 0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg_clustering, centers_df, X_train, y_train, X_test, y_test = rf_clustering(clean_dataset)\n",
    "results = evaluate(reg_clustering, X_test, y_test, silent=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
